---
title: "p8105_hw3_yw3439"
author: "Qetsiyah Wang"
date: "10/8/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(ggplot2)
library(hexbin)
```


## Problem 1 Instacart

```{r}

library(p8105.datasets)
data("instacart")

```
  The dataset instacart contains `r nrow(instacart)` observations and `r ncol(instacart)` variables, `r colnames(instacart)`. Instacart mainly discusses about details of each order for different customers, including order time, order quantity, reordered condition. Order_dow, order_hour_of_day show order time while placing each order. Reordered condition is mainly introduced in logical variable "reordered", order_number and days_since_prior_order. Also, instacart introduces products information for each order, `r colnames(instacart)[11:15]`. For example, the product, yellow onions and organic butternut squash belong to the aisle of fresh vegetables and the produce department.
  
```{r}

aisle = instacart %>%
  group_by(aisle) %>%
  summarize(ordered_number = n()) %>%
  arrange(-ordered_number)

aisle %>%
  filter(ordered_number > 10000) %>%
  mutate(
    aisle = fct_reorder(aisle, ordered_number)
  ) %>%
  ggplot(aes(x = ordered_number, y = aisle)) +
  geom_bar(stat = "identity", width = 1) +
  labs(title = "Ordered Number (>10000) for Each Aisle",
       x = "Ordered Number",
       y = "Aisle Name")

```

   Instacart shows that the `r str_to_title(pull(aisle, aisle)[1])` is the aisle that most items ordered from, with total order of `r pull(aisle, ordered_number)[1]`. Shown in the plot "Ordered Number (>10000) for Each Aisle", there are `r nrow(filter(aisle, ordered_number > 10000))` aisles containing ordered number of items more than 100000. Besides Fresh Vegetables, `r str_to_title(pull(aisle, aisle)[2])` show significantly high items ordered of `r pull(aisle, ordered_number)[2]`, than any else aisles.

```{r, message=FALSE}

baking = instacart %>%
  filter(aisle == "baking ingredients") %>%
  group_by(aisle, product_id, product_name) %>%
  summarize(order_number = sum(order_number)) %>%
  arrange(-order_number) %>%
  head(3)

dog = instacart %>%
  filter(aisle == "dog food care") %>%
  group_by(aisle, product_id, product_name) %>%
  summarize(order_number = sum(order_number)) %>%
  arrange(-order_number) %>%
  head(3) %>%
  full_join(baking)

most_popular_items = instacart %>%
  filter(aisle == "packaged vegetables fruits") %>%
  group_by(aisle, product_id, product_name) %>%
  summarize(order_number = sum(order_number)) %>%
  arrange(-order_number) %>%
  head(3) %>%
  full_join(dog)

knitr::kable(most_popular_items, caption = 'Three Most Popular Items for "Baking Ingredients", "Dog Food Care", "Packaged Vegetables Fruits')
```

  As shown in the table above, three most popular items for "Baking Ingredients" are `r pull(most_popular_items, product_name)[7:9]`, with order times of  `r pull(most_popular_items, order_number)[7:9]`, respectively. For "Dog Food Care", three most popular items are `r pull(most_popular_items, product_name)[4:6]`, with order times of `r pull(most_popular_items, order_number)[4:6]`, respectively. For "Packaged Vegetables Fruits", three most popular items are `r pull(most_popular_items, product_name)[1:3]`, with order times of `r pull(most_popular_items, order_number)[1:3]`, respectively.

```{r}

order_hour = instacart %>%
  select(product_name, order_dow, order_hour_of_day) %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>%
  mutate(
    order_dow = as.factor(order_dow),
    order_dow = recode(order_dow, "0" = "sunday", "1" = "monday", "2" = "tuesday", "3" = "wednesday",
                       "4" = "thursday", "5" = "friday", "6" = "saturday")
    ) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_order_hour = mean(order_hour_of_day, na.rm = TRUE)) %>%
  arrange(product_name, -mean_order_hour)

fine_order_hr = order_hour %>%
  arrange(order_dow) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_order_hour
  )

knitr::kable(fine_order_hr, caption = 'Mean Hour of Day for "Pink Lady Apples and "Coffee Ice Cream')

```

  Mean of hour of day for each week for "Pink Lady Apples" and "Coffee Ice Cream" is shown in the table above. From the table, for "Coffee Ice Cream", the highest mean order hour is `r pull(order_hour, mean_order_hour)[1]` on `r pull(order_hour, order_dow)[1]`. "Pink Lady Apples" shows the highest mean order hour of `r pull(order_hour, mean_order_hour)[8]` on `r pull(order_hour, order_dow)[8]`. Generally, coffee ice cream shows higher mean order hour than pink lady apples for 7 days within a week. 

## Problem 2 Accelerometers

```{r, message=FALSE}

accel_tidy = read_csv("accel_data.csv") %>%
  janitor::clean_names() %>%
  mutate(
    day_type = rep("weekday", 35),
    day_type = ifelse(day == "Sunday"| day == "Saturday", recode(day_type, "weekday" = "weekend"), "weekday")
  ) %>%
  select(-day_id) %>%
  mutate(
    day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday",
                                 "Saturday", "Sunday"))
  ) %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute_of_the_day",
    names_prefix = "activity_",
    values_to = "activity_counts"
  ) %>%
  arrange(day)

day_activity = accel_tidy %>%
  group_by(week, day_type, day) %>%
  summarize(total_activity = sum(activity_counts))

```

  Accelerometers mainly discusses the study on the physical activity of a 63 year-old male with BMI 25. The whole dataset contains `r ncol(accel_tidy)` variables, `r colnames(accel_tidy)`. 1440 activity counts, for every minute of 24-hour day for total 35 days, are all tidied into two variables, `r colnames(accel_tidy)[4]` and `r colnames(accel_tidy)[5]`, resulting final `r nrow(accel_tidy)` observations.
  Collecting activity accounts based on days, general physical activity for this participant is maintaining around `r mean(pull(day_activity, total_activity), na.rm=TRUE)`. Across through the whole study period of 35 days, there is no significant difference of his physical activity between weekday and weekend. The maximum of the physical activity is `r filter(day_activity, total_activity == max(pull(day_activity, total_activity)))[1]`. There are two abnormal data on Saturday in week 4 and week 5, which only show `r min(pull(day_activity, total_activity))`.

```{r}

accel_tidy %>%
  mutate(
    minute_of_the_day = factor(minute_of_the_day, levels = c(1:1440), ordered = TRUE)
  ) %>%
  ggplot(aes(x = minute_of_the_day, y = activity_counts, color = day)) +
  scale_x_discrete(
    breaks = seq(1, 1440, 60),
    labels = factor(1:24)
  ) +
  geom_line() +
  labs(
    title = "24-hour Inspection Activity time courses for each day",
    x = "Time course for one 24-Hour Day",
    y = "Activity Counts"
  )

```

  Based on the plot, from the aspect of 24-hour time course, it is obvious that two major parts of the physical activity for the participant are focusing on around 12pm and 9-11pm. Before 7am, the physical activity is lowest because this time period is sleeping time. From the aspect of days, the physical activity on Sunday is concentrating at noon, and that on Friday is focusing at night. For Saturday, the participant would show mildly higher physical activity at around 5pm.

## Problem 3 NY NOAA data

```{r}

library(p8105.datasets)
data("ny_noaa")
  
```
  NY NOAA  mainly presents a database about daily observations on climate in New York City for each day, starting from `r pull(ny_noaa, date)[1]`, containing `r nrow(ny_noaa)` observations. Observations are focused on several common weather parameters, `r colnames(ny_noaa)[3:7]`, presenting precipitation, snowfalls and temperature in NYC. Each parameter contains lots of missing values, especially for maximum temperature that has `r sum(is.na(ny_noaa$tmax))` missing values. Generally, this dataset needs further tidy steps.

```{r}

ny_climate = ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, c("year", "month", "day"))
```

```{r}

ny_climate %>%
  mutate(
    month = factor(month, levels = c("01", "02", "03", "04", "05",
                                     "06", "07", "08", "09", "10", "11", "12"), labels = month.name),
    tmax = as.numeric(tmax)/10,
    tmin = as.numeric(tmin)/10,
    prcp = prcp/10
  )

snow = ny_climate %>%
  mutate(
    snow = as.factor(snow)
  ) %>%
  group_by(snow) %>%
  summarize(count = n()) %>%
  arrange(-count)
```
 Original dataset uses tenth of the unit for three paraemeters: maximum temperature, minimum temperature and precipitation, which are all changed into reasonable unites through being divided by 10. For snowfalls, except missing values, the most common observed values are `r pull(snow, snow)[1]` with observations of `r pull(snow, count)[1]`.

```{r}

ny_climate %>%
  filter(month == "January" | month =="July") %>%
  ggplot(aes(y = tmax)) +
  geom_boxplot(aes(fill = month), alpha = 0.2) +
  facet_grid(.~month) +
  labs(title = "Average Temperature in January and July across Years",
       x = "Month",
       y = "Maximum Tempertaure in Degree C")

```

  Shown in the plot, the average maximum temperature in July is significantly higher than that in January, which does make sense because July is in summer and January is in winter. The boxplot for January is wider than the boxplot of July, meaning that the range for maximum temperature in July is smaller than that in January. Outliers exists for both months, which both occupies quite big proportion of the data because the transparent filling of outliers can increase into solid color while approaching to the average maximum temperature.

```{r}

ny_climate %>%
  ggplot(aes(x = tmax, y = tmin)) +
  geom_hex() +
  stat_binhex(na.rm = TRUE) +
  labs(
    title = "Maximum Temperature vs. Minimum Temperature",
    x = "Maximum Daily Temperature (C)",
    y = "Minimum Daily Temperature (C)"
  )

ny_climate %>%
  filter(snow > 0) %>%
  filter(snow < 100) %>%
  ggplot(aes(x = snow, color = year)) +
  geom_density(alpha = 0.2)
  
  

```
  
  
  
  
  
  
